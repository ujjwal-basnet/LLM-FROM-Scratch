{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05163791",
   "metadata": {},
   "source": [
    "To understand the mechanics of LlamaIndex, let's walk through a simplified numerical example. This will illustrate how text is transformed into numbers and how retrieval works.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c20948",
   "metadata": {},
   "source": [
    "# Step 1: document and chunking (breaking into node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "504e97ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "docuemnt1= \"The capital of Nepal is Kathmandu. Kathmandu is known for its rich history and ancient temples.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8295ff",
   "metadata": {},
   "source": [
    "LlamaIndex would first chunk this into smaller nodes. For simplicity, let's say we have two nodes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084965b8",
   "metadata": {},
   "source": [
    "Node =  \"The capital of Nepal is Kathmandu.\"\n",
    "\n",
    "Node 2= \"Kathmandu is known for its rich history and ancient temples.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431dfe54",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "542ee993",
   "metadata": {},
   "source": [
    "# Step 2: Vector Embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3556b54b",
   "metadata": {},
   "source": [
    "Next, an embedding model (like text-embedding-ada-002 from OpenAI) converts these nodes into numerical vectors. These are simplified, low-dimensional vectors for illustration; in reality, they have hundreds or thousands of dimensions.\n",
    "\n",
    "Vector for Node 1: [0.8, 0.2, -0.5]\n",
    "\n",
    "Vector for Node 2: [0.6, 0.7, 0.3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c525ed7",
   "metadata": {},
   "source": [
    "These vectors are stored in a VectorStoreIndex.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0518c99",
   "metadata": {},
   "source": [
    "# Step 4: Query Embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc12f5e1",
   "metadata": {},
   "source": [
    "The same embedding model converts the user's query into a vector:\n",
    "\n",
    "Query Vector: [0.7, 0.1, -0.4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38ecd52",
   "metadata": {},
   "source": [
    "# Step 5: Semantic Search (Cosine Similarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f0b295",
   "metadata": {},
   "source": [
    "The query engine now compares the query vector to the node vectors in the index to find the most similar one. A common method for this is cosine similarity, which measures the cosine of the angle between two vectors. A value closer to 1 indicates higher similarity.\n",
    "\n",
    "The formula for cosine similarity between two vectors A and B is:\n",
    "\n",
    "Cosine Similarity(A,B)= \n",
    "∥A∥∥B∥\n",
    "A⋅B\n",
    "​\n",
    " \n",
    "Similarity between Query and Node 1:\n",
    "\n",
    "Dot Product: (0.7 * 0.8) + (0.1 * 0.2) + (-0.4 * -0.5) = 0.56 + 0.02 + 0.2 = 0.78\n",
    "\n",
    "Magnitude of Query Vector: sqrt(0.7^2 + 0.1^2 + (-0.4)^2) = sqrt(0.49 + 0.01 + 0.16) = sqrt(0.66) ≈ 0.81\n",
    "\n",
    "Magnitude of Node 1 Vector: sqrt(0.8^2 + 0.2^2 + (-0.5)^2) = sqrt(0.64 + 0.04 + 0.25) = sqrt(0.93) ≈ 0.96\n",
    "\n",
    "Cosine Similarity: 0.78 / (0.81 * 0.96) ≈ 0.99\n",
    "\n",
    "Similarity between Query and Node 2:\n",
    "\n",
    "Dot Product: (0.7 * 0.6) + (0.1 * 0.7) + (-0.4 * 0.3) = 0.42 + 0.07 - 0.12 = 0.37\n",
    "\n",
    "Magnitude of Node 2 Vector: sqrt(0.6^2 + 0.7^2 + 0.3^2) = sqrt(0.36 + 0.49 + 0.09) = sqrt(0.94) ≈ 0.97\n",
    "\n",
    "Cosine Similarity: 0.37 / (0.81 * 0.97) ≈ 0.47\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b6a1e3",
   "metadata": {},
   "source": [
    "# Step 6: Retrieval and Response Generation\n",
    "The query engine sees that Node 1 has a much higher similarity score (0.99) than Node 2 (0.47). Therefore, it retrieves Node 1: \"The capital of Nepal is Kathmandu.\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
